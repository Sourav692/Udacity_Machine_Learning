{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boston Housing Data\n",
    "\n",
    "In order to gain a better understanding of the metrics used in regression settings, we will be looking at the Boston Housing dataset.  \n",
    "\n",
    "First use the cell below to read in the dataset and set up the training and testing data that will be used for the rest of this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "boston = load_boston()\n",
    "y = boston.target\n",
    "X = boston.data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 1:** Import all the models that can be used for regression problems using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import models from sklearn - notice you will want to use \n",
    "# the regressor version (not classifier) \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 2:** Now that you have imported the 4 models that can be used for regression problems, instantate each below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate each of the models you imported\n",
    "# For now use the defaults for all the hyperparameters\n",
    "\n",
    "tree_mod = DecisionTreeRegressor()\n",
    "rf_mod = RandomForestRegressor()\n",
    "ada_mod = AdaBoostRegressor()\n",
    "reg_mod = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 3:** Fit each of your instantiated models on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit each of your models using the training data\n",
    "tree_mod.fit(X_train, y_train)\n",
    "rf_mod.fit(X_train, y_train)\n",
    "ada_mod.fit(X_train, y_train)\n",
    "reg_mod.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 4:** Use each of your models to predict on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test values for each model\n",
    "\n",
    "preds_tree = tree_mod.predict(X_test) \n",
    "preds_rf = rf_mod.predict(X_test)\n",
    "preds_ada = ada_mod.predict(X_test)\n",
    "preds_reg = reg_mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 5:** Import the metrics that can be used in for regression problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the metrics from sklearn\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 6:** Similar to what you did with classification models, let's make sure you are comfortable with how exactly each of these metrics is being calculated.  We can then match the value to what sklearn provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.742954049517\n",
      "0.742954049517\n",
      "Since the above match, we can see that we have correctly calculated the r2 value.\n"
     ]
    }
   ],
   "source": [
    "def r2(actual, preds):\n",
    "    '''\n",
    "    INPUT:\n",
    "    actual - numpy array or pd series of actual y values\n",
    "    preds - numpy array or pd series of predicted y values\n",
    "    OUTPUT:\n",
    "    returns the r-squared score as a float\n",
    "    '''\n",
    "    sse = np.sum((actual-preds)**2)\n",
    "    sst = np.sum((actual-np.mean(actual))**2)\n",
    "    return 1 - sse/sst\n",
    "\n",
    "# Check solution matches sklearn\n",
    "print(r2(y_test, preds_tree))\n",
    "print(r2_score(y_test, preds_tree))\n",
    "print(\"Since the above match, we can see that we have correctly calculated the r2 value.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 7:** Let's check the same for mean_squared_error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.1532894737\n",
      "19.1532894737\n",
      "If the above match, you are all set!\n"
     ]
    }
   ],
   "source": [
    "def mse(actual, preds):\n",
    "    return np.sum((actual-preds)**2)/len(actual)\n",
    "\n",
    "\n",
    "# Check your solution matches sklearn\n",
    "print(mse(y_test, preds_tree))\n",
    "print(mean_squared_error(y_test, preds_tree))\n",
    "print(\"If the above match, you are all set!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 8:** Now one last time for mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.70921052632\n",
      "2.70921052632\n",
      "If the above match, you are all set!\n"
     ]
    }
   ],
   "source": [
    "def mae(actual, preds):\n",
    "    return np.sum(np.abs(actual-preds))/len(actual)\n",
    "\n",
    "# Check your solution matches sklearn\n",
    "print(mae(y_test, preds_tree))\n",
    "print(mean_absolute_error(y_test, preds_tree))\n",
    "print(\"If the above match, you are all set!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 9:** Which model performed the best in terms of each of the metrics?  Note that r2 and mse will always match, but the mae may give a different best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_true, preds, model_name=None):\n",
    "    '''\n",
    "    INPUT:\n",
    "    y_true - the y values that are actually true in the dataset (numpy array or pandas series)\n",
    "    preds - the predictions for those values from some model (numpy array or pandas series)\n",
    "    model_name - (str - optional) a name associated with the model if you would like to add it to the print statements \n",
    "    \n",
    "    OUTPUT:\n",
    "    None - prints the mse, mae, r2\n",
    "    '''\n",
    "    if model_name == None:\n",
    "        print('Mean Squared Error: ', format(mean_squared_error(y_true, preds)))\n",
    "        print('Mean Absolute Error: ', format(mean_absolute_error(y_true, preds)))\n",
    "        print('R2 Score: ', format(r2_score(y_true, preds)))\n",
    "        print('\\n\\n')\n",
    "    \n",
    "    else:\n",
    "        print('Mean Squared Error ' + model_name + ' :' , format(mean_squared_error(y_true, preds)))\n",
    "        print('Mean Absolute Error ' + model_name + ' :', format(mean_absolute_error(y_true, preds)))\n",
    "        print('R2 Score ' + model_name + ' :', format(r2_score(y_true, preds)))\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error tree : 19.15328947368421\n",
      "Mean Absolute Error tree : 2.7092105263157893\n",
      "R2 Score tree : 0.7429540495168494\n",
      "\n",
      "\n",
      "\n",
      "Mean Squared Error random forest : 12.878902631578946\n",
      "Mean Absolute Error random forest : 2.3615789473684203\n",
      "R2 Score random forest : 0.827159205594287\n",
      "\n",
      "\n",
      "\n",
      "Mean Squared Error adaboost : 15.90735613078601\n",
      "Mean Absolute Error adaboost : 2.8577029681435886\n",
      "R2 Score adaboost : 0.7865159673000368\n",
      "\n",
      "\n",
      "\n",
      "Mean Squared Error linear reg : 21.54021894393166\n",
      "Mean Absolute Error linear reg : 3.1656052314924907\n",
      "R2 Score linear reg : 0.7109203586326288\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Decision Tree scores\n",
    "print_metrics(y_test, preds_tree, 'tree')\n",
    "\n",
    "# Print Random Forest scores\n",
    "print_metrics(y_test, preds_rf, 'random forest')\n",
    "\n",
    "# Print AdaBoost scores\n",
    "print_metrics(y_test, preds_ada, 'adaboost')\n",
    "\n",
    "# Linear Regression scores\n",
    "print_metrics(y_test, preds_reg, 'linear reg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the random forest performs the best."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
